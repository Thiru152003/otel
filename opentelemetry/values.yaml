# Default values for opentelemetry-collector
image:
  repository: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib
  tag: 0.86.0  # Consider using a more recent version if available
  pullPolicy: IfNotPresent
  pullSecrets: []  # Add if pulling from private registry

mode: deployment  # deployment, daemonset, statefulset, or sidecar

serviceAccount:
  create: true
  name: ""
  annotations: {}  # Add IAM role annotations if needed (especially for AWS)

rbac:
  create: true
  rules: []  # Add custom rules if needed

service:
  type: LoadBalancer
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
    # Consider adding internal annotation if collectors should be internal only
    # service.beta.kubernetes.io/aws-load-balancer-internal: "true"
  ports:
    otlp-grpc: 4317
    otlp-http: 4318
    metrics: 8888
    jaeger-thrift: 14268
    zipkin: 9411
  # Add if you need internal cluster service
  internal:
    type: ClusterIP
    annotations: {}
    ports: {}  # Same ports as above if needed

config:
  exporters:
    logging:
      loglevel: info
    prometheus:
      endpoint: "0.0.0.0:8889"
    # Consider adding other exporters like:
    # otlp:
    #   endpoint: otel-collector:4317
  receivers:
    otlp:
      protocols:
        grpc:
        http:
    jaeger:
      protocols:
        thrift_http:
    zipkin:
    # Consider adding hostmetrics for node monitoring
    hostmetrics:
      collection_interval: 10s
      scrapers:
        cpu: {}
        memory: {}
        disk: {}
        network: {}
        load: {}
  processors:
    batch: {}  # Recommended for production
    memory_limiter:
      check_interval: 1s
      limit_mib: 400
      spike_limit_mib: 100
  service:
    pipelines:
      traces:
        receivers: [otlp, jaeger, zipkin]
        processors: [batch]
        exporters: [logging]
      metrics:
        receivers: [otlp, hostmetrics]
        processors: [batch]
        exporters: [logging, prometheus]
      logs:
        receivers: [otlp]
        processors: [batch]
        exporters: [logging]

resources:
  limits:
    cpu: 1000m  # Increased for production
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 256Mi

autoscaling:
  enabled: true  # Enabled for production
  minReplicas: 2  # At least 2 for HA
  maxReplicas: 5
  targetCPUUtilizationPercentage: 60
  targetMemoryUtilizationPercentage: 60

podDisruptionBudget:
  enabled: true  # Important for production
  minAvailable: 1

nodeSelector: {}  # Add if needed
tolerations: []   # Add if needed
affinity: {}      # Add if needed

grafana:
  enabled: true
  adminPassword: admin
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default
  dashboards:
    default:
      otel-collector-dashboard:
        gnetId: 12559
        revision: 1
        datasource: Prometheus

prometheusOperator:
  serviceMonitor:
    enabled: true  # Recommended if using Prometheus Operator
    interval: 30s
    scrapeTimeout: 10s
    selector:
      matchLabels: {}
    relabelings: []
    metricRelabelings: []

  podMonitor:
    enabled: false
    interval: 30s
    scrapeTimeout: 10s
    selector:
      matchLabels: {}

# Add these if needed
extraVolumes: []
extraVolumeMounts: []
env: []
podAnnotations: {}
podSecurityContext: {}
securityContext: {}
